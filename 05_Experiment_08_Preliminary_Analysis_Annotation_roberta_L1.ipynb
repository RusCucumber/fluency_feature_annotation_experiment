{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/21 (Tue) | Experiment\n",
    "\n",
    "# Preliminary Analyses of Annoation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook conducts preliminary analyses.\n",
    "The goal of current analyses is to fill the following table.\n",
    "\n",
    "| Task | WER | N disfluency (Manual / Automatic) | N MCP (Manual / Automatic) | N ECP (Manual / Automatic) |\n",
    "| - | - | - | - | - |\n",
    "| WoZ_Interview |  |  |  |  |\n",
    "\n",
    "Before starting the analyses, the following code block loads required packages and define global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Generator, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jiwer import wer\n",
    "\n",
    "from utils.mfr import logit_2_rating\n",
    "\n",
    "DATA_DIR = Path(\"/home/matsuura/Development/app/feature_extraction_api/experiment/data\")\n",
    "\n",
    "MONOLOGUE_TASK = []\n",
    "DIALOGUE_TASK = [\"WoZ_Interview\"]\n",
    "\n",
    "FILLER = {\"uh\", \"ah\", \"um\", \"mm\", \"hmm\", \"oh\", \"mm-hmm\", \"er\", \"mhm\", \"uh-huh\", \"er\", \"erm\", \"huh\", \"uhu\", \"mmhmm\", \"uhhuh\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Define Functions\n",
    "\n",
    "This section defines functions for the preliminary analyses.\n",
    "The following code block defines two functions; one generates csv file paths of manual and automatic annotation results; and another one loads them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_result_csv_path_generator(task: str, rating_filter: Optional[List[int]] =None) -> Generator[Tuple[Path, Path], None, None]:\n",
    "    load_dir = DATA_DIR / f\"{task}/10_SCTK_Inputs\"\n",
    "\n",
    "    if rating_filter is None:\n",
    "        for manu_csv_path in load_dir.glob(\"*_manu.csv\"):\n",
    "            filename = manu_csv_path.stem.removesuffix(\"_manu\")\n",
    "            auto_csv_path = load_dir / f\"{filename}_auto_roberta_L1.csv\"\n",
    "\n",
    "            yield manu_csv_path, auto_csv_path\n",
    "    else:\n",
    "        pf_path = DATA_DIR / f\"{task}/12_PF_Rating/pf_rating.csv\"\n",
    "        df_pf = pd.read_csv(pf_path)\n",
    "        uid_list = df_pf[\"uid\"].to_numpy()\n",
    "\n",
    "        logit_path = pf_path.parent / \"logit.csv\"\n",
    "        threshold_path = logit_path.parent / \"threshold.csv\"\n",
    "        \n",
    "        df_logit = pd.read_csv(logit_path, index_col=0)\n",
    "        rating_list = logit_2_rating(df_logit[\"theta\"], threshold_path)\n",
    "\n",
    "        mask = np.full(rating_list.shape, False, dtype=bool)\n",
    "        for rating in rating_filter:\n",
    "            mask = mask | (rating_list == rating)\n",
    "        \n",
    "        uid_list = uid_list[mask]\n",
    "\n",
    "        for uid in uid_list:\n",
    "            if task == \"WoZ_Interview\":\n",
    "                uid = str(int(uid)).zfill(3)\n",
    "\n",
    "            filename_pattern = f\"{uid}*_manu.csv\"\n",
    "            for manu_csv_path in load_dir.glob(filename_pattern):\n",
    "                filename = manu_csv_path.stem.removesuffix(\"_manu\")\n",
    "                auto_csv_path = load_dir / f\"{filename}_auto_bert.csv\"\n",
    "\n",
    "                yield manu_csv_path, auto_csv_path\n",
    "\n",
    "def load_dataset(\n",
    "        rating_filter_monologue: Optional[List[int]] =None,\n",
    "        rating_filter_dialogue: Optional[List[int]] =None,\n",
    ") -> Dict[str, Dict[str, List[Dict[str, pd.DataFrame]]]]:\n",
    "    dataset = {\n",
    "        \"monologue\": {},\n",
    "        \"dialogue\": {}\n",
    "    }\n",
    "    \n",
    "    for monologue_task in MONOLOGUE_TASK:\n",
    "        dataset[\"monologue\"][monologue_task] = []\n",
    "        \n",
    "        for manu_csv_path, auto_csv_path in annotation_result_csv_path_generator(monologue_task, rating_filter=rating_filter_monologue):\n",
    "            df_manu = pd.read_csv(manu_csv_path)\n",
    "            df_auto = pd.DataFrame([], columns=[\"text\"])\n",
    "            if auto_csv_path.exists():\n",
    "                df_auto = pd.read_csv(auto_csv_path)\n",
    "\n",
    "            dataset[\"monologue\"][monologue_task].append({\n",
    "                \"manual\": df_manu,\n",
    "                \"automatic\": df_auto\n",
    "            })\n",
    "\n",
    "    for dialogue_task in DIALOGUE_TASK:\n",
    "        dataset[\"dialogue\"][dialogue_task] = []\n",
    "\n",
    "        for manu_csv_path, auto_csv_path in annotation_result_csv_path_generator(dialogue_task, rating_filter=rating_filter_dialogue):\n",
    "            df_manu = pd.read_csv(manu_csv_path, na_values=[\"\", \" \"], keep_default_na=False)\n",
    "            df_auto = pd.DataFrame([], columns=[\"text\"])\n",
    "            if auto_csv_path.exists():\n",
    "                df_auto = pd.read_csv(auto_csv_path, na_values=[\"\", \" \"], keep_default_na=False)\n",
    "\n",
    "            dataset[\"dialogue\"][dialogue_task].append({\n",
    "                \"manual\": df_manu,\n",
    "                \"automatic\": df_auto\n",
    "            })\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to calculate WER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer(annotation_results: List[Dict[str, pd.DataFrame]], remove_filer: bool =False) -> float:\n",
    "    ref = []\n",
    "    hyp = []\n",
    "\n",
    "    for annotation_result in annotation_results:\n",
    "        df_manu = annotation_result[\"manual\"]\n",
    "        df_auto = annotation_result[\"automatic\"]\n",
    "\n",
    "        mask_tag_manu = df_manu[\"text\"].astype(str).str.endswith(\">\")\n",
    "        mask_tag_auto = df_auto[\"text\"].astype(str).str.endswith(\">\")\n",
    "\n",
    "        df_manu = df_manu[~mask_tag_manu]\n",
    "        df_auto = df_auto[~mask_tag_auto]\n",
    "\n",
    "        if remove_filer:\n",
    "            for filler in FILLER:\n",
    "                mask_filler_manu = (df_manu[\"text\"] == filler)\n",
    "                df_manu = df_manu[~mask_filler_manu]\n",
    "\n",
    "                mask_filler_auto = (df_auto[\"text\"] == filler)\n",
    "                df_auto = df_auto[~mask_filler_auto]\n",
    "\n",
    "        text_manu = \" \".join(df_manu[\"text\"].astype(str))\n",
    "        text_auto = \" \".join(df_auto[\"text\"].astype(str))\n",
    "\n",
    "        if len(text_manu) == 0 or len(text_auto) == 0:\n",
    "            continue\n",
    "\n",
    "        ref.append(text_manu)\n",
    "        hyp.append(text_auto)\n",
    "\n",
    "    return wer(ref, hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to count the number of tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tags(annotation_results: List[Dict[str, pd.DataFrame]], target_tag: str) -> Tuple[List[int], List[int]]:\n",
    "    n_tag_manu = []\n",
    "    n_tag_auto = []\n",
    "\n",
    "    for annotation_result in annotation_results:\n",
    "        df_manu = annotation_result[\"manual\"]\n",
    "        df_auto = annotation_result[\"automatic\"]\n",
    "\n",
    "        mask_tag_manu = (df_manu[\"text\"] == target_tag)\n",
    "        mask_tag_auto = (df_auto[\"text\"] == target_tag)\n",
    "\n",
    "        n_tag_manu.append(mask_tag_manu.sum())\n",
    "        n_tag_auto.append(mask_tag_auto.sum())\n",
    "\n",
    "    return n_tag_manu, n_tag_auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Preliminary Analyses\n",
    "\n",
    "This section conducts the preliminary analyses.\n",
    "The following code block loads entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. WER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block calculate WER of a dialogue task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER of WoZ_Interview = 0.15021711724331138\n"
     ]
    }
   ],
   "source": [
    "dialogue_data = []\n",
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    res = calculate_wer(annotation_results, remove_filer=True)\n",
    "\n",
    "    print(f\"WER of {dialogue_task} = {res}\")\n",
    "\n",
    "    dialogue_data += annotation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Count Disfluency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts the number of disfluency words in dialogue tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_disfluency of WoZ_Interview = 3935\n",
      "[Automatic] N_disfluency of WoZ_Interview = 3178\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<DISFLUENCY>\")\n",
    "\n",
    "    print(f\"[Manual] N_disfluency of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_disfluency of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Count Mid-Clause Pauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts the number of MCP in dialogue tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_MCP of WoZ_Interview = 7574\n",
      "[Automatic] N_MCP of WoZ_Interview = 10316\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<CI>\")\n",
    "\n",
    "    print(f\"[Manual] N_MCP of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_MCP of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Count End-Clause Pauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts the number of ECP in dialogue tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_ECP of WoZ_Interview = 2414\n",
      "[Automatic] N_ECP of WoZ_Interview = 2652\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<CE>\")\n",
    "\n",
    "    print(f\"[Manual] N_ECP of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_ECP of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Summary\n",
    "\n",
    "As results, the following table was obtained.\n",
    "\n",
    "| Task | WER | N disfluency (Manual / Auto_RoBERTa / Auto_RoBERTa_L1) | N MCP (Manual / Auto_RoBERTa / Auto_RoBERTa_L1) | N ECP (Manual / Auto_RoBERTa / Auto_RoBERTa_L1) |\n",
    "| - | - | - | - | - |\n",
    "| WoZ_Interview | 15.0% | 3,935 / 3,514 / 3,178 | 7,574 / 10,322 / 10,316 | 2,414 / 2,646 / 2,652 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Additional Analyses\n",
    "\n",
    "This section conducts the same analyses for each PF groups.\n",
    "\n",
    "### 5.1. Beginners\n",
    "\n",
    "The following code block loads beginners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "beginner_dataset = load_dataset(rating_filter_monologue=[0, 1, 2], rating_filter_dialogue=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block calculates WER of beginners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER of WoZ_Interview = 0.2485251852972319\n"
     ]
    }
   ],
   "source": [
    "dialogue_data = []\n",
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = beginner_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    res = calculate_wer(annotation_results, remove_filer=True)\n",
    "\n",
    "    print(f\"WER of {dialogue_task} = {res}\")\n",
    "\n",
    "    dialogue_data += annotation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts disfluency tags in beginners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_disfluency of WoZ_Interview = 955\n",
      "[Automatic] N_disfluency of WoZ_Interview = 573\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = beginner_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<DISFLUENCY>\")\n",
    "\n",
    "    print(f\"[Manual] N_disfluency of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_disfluency of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts MCP tags in beginners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_MCP of WoZ_Interview = 1913\n",
      "[Automatic] N_MCP of WoZ_Interview = 2061\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = beginner_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<CI>\")\n",
    "\n",
    "    print(f\"[Manual] N_MCP of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_MCP of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts ECP tags in beginners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_ECP of WoZ_Interview = 472\n",
      "[Automatic] N_ECP of WoZ_Interview = 451\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = beginner_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<CE>\")\n",
    "\n",
    "    print(f\"[Manual] N_ECP of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_ECP of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Intemediate\n",
    "\n",
    "The following code block loads intermediate group's speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "intemediate_dataset = load_dataset(rating_filter_monologue=[3, 4, 5], rating_filter_dialogue=[2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block calculates WER of intemediate learners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER of WoZ_Interview = 0.14034321645342998\n"
     ]
    }
   ],
   "source": [
    "dialogue_data = []\n",
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = intemediate_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    res = calculate_wer(annotation_results, remove_filer=True)\n",
    "\n",
    "    print(f\"WER of {dialogue_task} = {res}\")\n",
    "\n",
    "    dialogue_data += annotation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts disfluency tags in intemediate learners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_disfluency of WoZ_Interview = 2662\n",
      "[Automatic] N_disfluency of WoZ_Interview = 1790\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = intemediate_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<DISFLUENCY>\")\n",
    "\n",
    "    print(f\"[Manual] N_disfluency of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_disfluency of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts MCP tags in intemediate learners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_MCP of WoZ_Interview = 4911\n",
      "[Automatic] N_MCP of WoZ_Interview = 6996\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = intemediate_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<CI>\")\n",
    "\n",
    "    print(f\"[Manual] N_MCP of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_MCP of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts ECP tags in intermediate learners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_ECP of WoZ_Interview = 1682\n",
      "[Automatic] N_ECP of WoZ_Interview = 1839\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = intemediate_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<CE>\")\n",
    "\n",
    "    print(f\"[Manual] N_ECP of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_ECP of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Advanced \n",
    "\n",
    "The following code block loads advanced learners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_dataset = load_dataset(rating_filter_monologue=[6, 7, 8], rating_filter_dialogue=[4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block calculates WER of advanced learners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER of WoZ_Interview = 0.081675562024907\n"
     ]
    }
   ],
   "source": [
    "dialogue_data = []\n",
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = advanced_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    res = calculate_wer(annotation_results, remove_filer=True)\n",
    "\n",
    "    print(f\"WER of {dialogue_task} = {res}\")\n",
    "\n",
    "    dialogue_data += annotation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts disfluency tags in advanced learners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_disfluency of WoZ_Interview = 318\n",
      "[Automatic] N_disfluency of WoZ_Interview = 214\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = advanced_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<DISFLUENCY>\")\n",
    "\n",
    "    print(f\"[Manual] N_disfluency of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_disfluency of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts MCP tags in advanced learners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_MCP of WoZ_Interview = 750\n",
      "[Automatic] N_MCP of WoZ_Interview = 1231\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = advanced_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<CI>\")\n",
    "\n",
    "    print(f\"[Manual] N_MCP of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_MCP of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block counts ECP tags in advanced learners' speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Manual] N_ECP of WoZ_Interview = 260\n",
      "[Automatic] N_ECP of WoZ_Interview = 390\n"
     ]
    }
   ],
   "source": [
    "for dialogue_task in DIALOGUE_TASK:\n",
    "    annotation_results = advanced_dataset[\"dialogue\"][dialogue_task]\n",
    "\n",
    "    n_tags_manu, n_tags_auto = count_tags(annotation_results, \"<CE>\")\n",
    "\n",
    "    print(f\"[Manual] N_ECP of {dialogue_task} = {sum(n_tags_manu)}\")\n",
    "    print(f\"[Automatic] N_ECP of {dialogue_task} = {sum(n_tags_auto)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teai-incremental-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
