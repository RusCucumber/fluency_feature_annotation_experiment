{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/14 (Tue) | Experiment\n",
    "\n",
    "# Evaluation of Reliability of Automatic Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook evalutate the reliability of the proposed automatic temporal feature annotation system.\n",
    "More specifically, I evaluate the system in terms of the following metrics.\n",
    "\n",
    "- Cohen's kappa\n",
    "- Accuracy score\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "\n",
    "Before starting the evaluation, the following code block loads required packages and defines global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Generator, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from utils.mfr import logit_2_rating\n",
    "from utils.cohen_kappa import RCohenKappa\n",
    "r_cohen_kappa = RCohenKappa(debug=False)\n",
    "\n",
    "DATA_DIR = Path(\"/home/matsuura/Development/app/feature_extraction_api/experiment/data\")\n",
    "\n",
    "TASK = [\"Arg_Oly\", \"Cartoon\", \"RtSwithoutRAA\", \"RtSwithRAA\", \"WoZ_Interview\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Define Functions\n",
    "\n",
    "This section defines functions for the analyses.\n",
    "The following code block defines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_generator(\n",
    "        task: str,\n",
    "        ignore_tag: str, \n",
    "        tags: Tuple[str] =(\"<disfluency>\", \"<ci>\", \"<ce>\", \"<filler>\"), \n",
    "        word: str =\"<word>\",\n",
    "        rating_filter: Optional[List[int]] =None,\n",
    "        bert: bool =False\n",
    ") -> Generator[Tuple[list, list], None, None]:\n",
    "    load_dir = DATA_DIR / f\"{task}/11_SCTK_Outputs\"\n",
    "\n",
    "    pf_path = DATA_DIR / f\"{task}/12_PF_Rating/pf_rating.csv\"\n",
    "    df_pf = pd.read_csv(pf_path)\n",
    "    uid_list = df_pf[\"uid\"].to_numpy()\n",
    "\n",
    "    if rating_filter is not None:\n",
    "        logit_path = pf_path.parent / \"logit_all.csv\"\n",
    "        threshold_path = logit_path.parent / \"threshold_all.csv\"\n",
    "        \n",
    "        df_logit = pd.read_csv(logit_path, index_col=0)\n",
    "        rating_list = logit_2_rating(df_logit[\"theta\"], threshold_path)\n",
    "\n",
    "        mask = np.full(rating_list.shape, False, dtype=bool)\n",
    "        for rating in rating_filter:\n",
    "            mask = mask | (rating_list == rating)\n",
    "        \n",
    "        uid_list = uid_list[mask]\n",
    "\n",
    "    for uid in uid_list:\n",
    "        if task == \"WoZ_Interview\":\n",
    "            uid = str(int(uid)).zfill(3)\n",
    "\n",
    "        filename_pattern = f\"{uid}*_ignore_{ignore_tag}.txt\"\n",
    "        if bert:\n",
    "            filename_pattern = f\"{uid}*_ignore_{ignore_tag}_bert.txt\"\n",
    "        for filename in load_dir.glob(filename_pattern):\n",
    "            with open(filename, \"r\") as f:\n",
    "                true = []\n",
    "                pred = []\n",
    "                flag = 0\n",
    "\n",
    "                for line in f.readlines():\n",
    "                    if line[0] == \"<\":\n",
    "                        continue\n",
    "\n",
    "                    line = line.replace(\"\\n\", \"\")\n",
    "\n",
    "                    if len(line) == 1 and line.isupper():\n",
    "                        flag += 1\n",
    "                        continue\n",
    "\n",
    "                    line = line.replace(\"\\\"\", \"\")\n",
    "                    if not(line in tags):\n",
    "                        line = word\n",
    "\n",
    "                    if flag == 1:\n",
    "                        true.append(line)\n",
    "                        flag += 1\n",
    "                    elif flag == 2:\n",
    "                        pred.append(line)\n",
    "                        flag = 0\n",
    "\n",
    "            yield true, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to convert labels to ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_2_id(\n",
    "        tag_list: List[str], \n",
    "        tags: List[str] =[\"<disfluency>\", \"<ci>\", \"<ce>\", \"<filler>\", \"<word>\"]\n",
    ") -> List[str]:\n",
    "    tag_id_list = []\n",
    "    for tag in tag_list:\n",
    "        if tag == \"<ce>\":\n",
    "            tag = \"<ci>\"\n",
    "\n",
    "        i = tags.index(tag)\n",
    "        tag_id_list.append(i)\n",
    "\n",
    "    return tag_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to calculate Cronbach's Alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cronbach_alpha(true: List[int], pred: List[int]):\n",
    "    mtx = np.array([true, pred])\n",
    "    var_by_items = np.var(mtx, axis=0)\n",
    "    sum_var_by_items = np.sum(var_by_items)\n",
    "\n",
    "    items_sum = np.sum(mtx, axis=1)\n",
    "    var_items_sum = np.var(items_sum)\n",
    "\n",
    "    n_items = len(true)\n",
    "\n",
    "    alpha = n_items / (n_items - 1) * (1 - sum_var_by_items / var_items_sum)\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to calculate reliability metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reliability(\n",
    "        task_list: List[str], \n",
    "        ignore_tag: str,\n",
    "        rating_filter: Optional[List[int]] =None\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    if ignore_tag == \"<CI>-<CE>-<FILLER>\":\n",
    "        tags = [\"<disfluency>\", \"<word>\"]\n",
    "        print(f\"--- Analysis of Disfluency ---\")\n",
    "\n",
    "    elif ignore_tag == \"<CI>-<CE>\":\n",
    "        tags = [\"<disfluency>\", \"<filler>\", \"<word>\"]\n",
    "        print(f\"--- Analysis of Disfluency & Filler ---\")\n",
    "\n",
    "    elif ignore_tag == \"<DISFLUENCY>-<FILLER>\":\n",
    "        tags = [\"<ci>\", \"<ce>\", \"<word>\"]\n",
    "        print(f\"--- Analysis of Pause Location ---\")\n",
    "\n",
    "    print(\"- Tasks ... \", end=\"\")\n",
    "\n",
    "    sample_size = 0\n",
    "    n_data = 0\n",
    "    for task in task_list:\n",
    "        print(f\"{task}, \", end=\"\")\n",
    "        for true, pred in label_generator(task, ignore_tag, rating_filter=rating_filter):\n",
    "            true = tag_2_id(true, tags=tags)\n",
    "            pred = tag_2_id(pred, tags=tags)\n",
    "\n",
    "            all_true += true\n",
    "            all_pred += pred\n",
    "            sample_size += len(true)\n",
    "            n_data += 1\n",
    "\n",
    "    if rating_filter is not None:\n",
    "        print(f\"\\n- Target rating ... {rating_filter}\")\n",
    "    else:\n",
    "        print()\n",
    "    print(f\"- Sample size = {sample_size}\")\n",
    "    print(f\"- Data size   = {n_data}\")\n",
    "\n",
    "    acc = accuracy_score(all_true, all_pred)\n",
    "    p, r, f, _ = precision_recall_fscore_support(all_true, all_pred)\n",
    "    # a = cronbach_alpha(all_true, all_pred)\n",
    "    kappa, _, lower, upper = r_cohen_kappa.cohen_kappa(all_true, all_pred)\n",
    "\n",
    "    print(f\"\\n- Metrics\")\n",
    "    # print(f\"\\tCronbach Alpha: {a}\")\n",
    "    print(f\"\\tCohen's Kappa:  {kappa:.03f} (|{lower:.03f} - {upper:.03f}|)\")\n",
    "    print(f\"\\tAccuracy:       {acc:.03f}\\n\")\n",
    "\n",
    "    print(f\"\\tLabels    | {np.array(tags)}\")\n",
    "    print(f\"\\tPrecision | {p}\") \n",
    "    print(f\"\\tRecall    | {r}\")\n",
    "    print(f\"\\tF1 score  | {f}\")\n",
    "\n",
    "    data_kappa = [[f\"{n_data:,}\", f\"{sample_size:,}\", f\"{kappa:.03f}\",f\"[{lower:.03f}, {upper:.03f}]\"]]\n",
    "    df_kappa = pd.DataFrame(data_kappa, columns=[\"N_data\", \"Sample size\", \"Kappa\", \"95% CI\"])\n",
    "    if \"<CI>-<CE>\" in ignore_tag:\n",
    "        data_cfmx = [[f\"{p[0]:.03f}\", f\"{r[0]:.03f}\", f\"{f[0]:.03f}\"]]\n",
    "        df_cfmx = pd.DataFrame(data_cfmx, columns=[\"P_disfl\", \"R_disfl\", \"F1_disfl\"])\n",
    "    else:\n",
    "        data_cfmx = [[f\"{p[0]:.03f}\", f\"{r[0]:.03f}\", f\"{f[0]:.03f}\", f\"{p[1]:.03f}\", f\"{r[1]:.03f}\", f\"{f[1]:.03f}\"]]\n",
    "        df_cfmx = pd.DataFrame(data_cfmx, columns=[\"P_mcp\", \"R_mcp\", \"F1_mcp\", \"P_ecp\", \"R_ecp\", \"F1_ecp\"])\n",
    "    \n",
    "    if rating_filter is None:\n",
    "        idx_name = f\"{task}_00All\"\n",
    "    elif rating_filter == [0, 1, 2] or rating_filter == [0, 1]:\n",
    "        idx_name = f\"{task}_01Low\"\n",
    "    elif rating_filter == [3, 4, 5] or rating_filter == [2, 3]:\n",
    "        idx_name = f\"{task}_02Mid\"\n",
    "    else:\n",
    "        idx_name = f\"{task}_03High\"\n",
    "    \n",
    "    df_kappa.index = [idx_name]\n",
    "    df_cfmx.index = [idx_name]\n",
    "\n",
    "    return df_kappa, df_cfmx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Reliability Analyses\n",
    "\n",
    "This section conducts reliability analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Pause Location Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kappa_pl_list = []\n",
    "df_cfmx_pl_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. All Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analysis of Pause Location ---\n",
      "- Tasks ... Arg_Oly, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cartoon, RtSwithoutRAA, RtSwithRAA, WoZ_Interview, \n",
      "- Sample size = 161603\n",
      "- Data size   = 2255\n",
      "\n",
      "- Metrics\n",
      "\tCohen's Kappa:  0.741 (|0.738 - 0.745|)\n",
      "\tAccuracy:       0.900\n",
      "\n",
      "\tLabels    | ['<ci>' '<ce>' '<word>']\n",
      "\tPrecision | [0.75216436 0.95770632]\n",
      "\tRecall    | [0.87455609 0.90789796]\n",
      "\tF1 score  | [0.80875595 0.93213724]\n"
     ]
    }
   ],
   "source": [
    "_, _ = evaluate_reliability(TASK, ignore_tag=\"<DISFLUENCY>-<FILLER>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teai-incremental-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
