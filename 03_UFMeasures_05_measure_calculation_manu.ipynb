{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/12 (Sun) | UF Measures\n",
    "\n",
    "# UF Measure Calculation Based on Manual Annotation (Dialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Thise notebook calculates UF measures from manual annotation of spoken dialogue corpus.\n",
    "The measure calculation consist of the following procedures.\n",
    "\n",
    "1. Load required files\n",
    "\n",
    "    a. Load a TextGrid file\n",
    "    b. Load the corresponding rev transcript\n",
    "\n",
    "2. Get start and end time from two adjacent turns\n",
    "\n",
    "    a. Convert the loaded rev transcript to turn-wise </br>\n",
    "    b. Concatnate user's turn-wise and system's original transcript </br>\n",
    "    c. Iterate two adjacent turns of system and user </br>\n",
    "    d. Extract start and end time from the two turns\n",
    "\n",
    "3. Based on the start and end time, get transcript, pauses, fillers and disfluency intervals.\n",
    "4. Count the number of pruned syllables\n",
    "\n",
    "    a. Count the number of syllables from the obtained transcript intervals (N_syl) </br>\n",
    "    b. Count the number of syllables from obtained fillers and disfluency intervals (N_syl_disfl) </br>\n",
    "    c. Calculate N_syl - N_syl_disfl (i.e., pruning)\n",
    "\n",
    "5. Get duration of the turn\n",
    "\n",
    "    a. Get earlies (start_time) and latest (end_time) timestamp from the obtained transcript, filler and disfluency intervals </br>\n",
    "    b. Calculate end_time - start_time\n",
    "\n",
    "6. Get pauses of the turn\n",
    "\n",
    "    a. From pause intervals generate lists of MCP and ECP durations </br>\n",
    "    b. From filler intervals count the number of fillers\n",
    "\n",
    "7. Get disfluency of the turn\n",
    "    \n",
    "    a. From disfluency intervals count the number of disfluency\n",
    "\n",
    "8. Set parameters calcuated in the procedure 4 to 7\n",
    "9. Based on the parameters claculate UF measures using UtteranceFluencyFeatureExtractor\n",
    "\n",
    "    Note. ignore detailed disfluency ratio measures and word-wise measures\n",
    "\n",
    "Before starting the procedures, the following code block loads required packages and define global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import List, Tuple, Generator\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textgrids import TextGrid, Interval\n",
    "import syllables\n",
    "\n",
    "from utils.transcript import convert_turnwise\n",
    "\n",
    "sys.path.append(\n",
    "    \"/home/matsuura/Development/app/feature_extraction_api/app/modules\"\n",
    ")\n",
    "\n",
    "from fluency import UtteranceFluencyFeatureExtractor\n",
    "\n",
    "DATA_DIR = Path(\"/home/matsuura/Development/app/feature_extraction_api/experiment/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Define Functions\n",
    "\n",
    "This section defines function to conduct procedures. \n",
    "First, the following code block defines a generator to yield a textgrid path and a function to load a TextGrid object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textgrid_path_generator() -> Generator[Path, None, None]:\n",
    "    load_dir = DATA_DIR / \"WoZ_Interview/01_Manual_TextGrid\"\n",
    "\n",
    "    for textgrid_path in load_dir.glob(\"*.TextGrid\"):\n",
    "        yield textgrid_path\n",
    "\n",
    "def load_textgrid(textgrid_path: Path) -> TextGrid:\n",
    "    textgrid = TextGrid(str(textgrid_path))\n",
    "\n",
    "    return textgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to load a rev transcript as padans' DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_transcript(textgrid_path: Path) -> pd.DataFrame:\n",
    "    filename = textgrid_path.stem\n",
    "    uid = filename.split(\"_\")[1]\n",
    "\n",
    "    load_path = DATA_DIR / f\"WoZ_Interview/01_Manual_TextGrid/{uid}.csv\"\n",
    "    df_transcript = pd.read_csv(load_path)\n",
    "\n",
    "    return df_transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to concat user's turn-wise and system's original transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_transcript(\n",
    "        df_transcript: pd.DataFrame,\n",
    "        df_transcript_turn: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    mask_system = df_transcript[\"speaker\"] == \"system\"\n",
    "    mask_user = df_transcript_turn[\"speaker\"] == \"user\"\n",
    "\n",
    "    df_system = df_transcript[mask_system]\n",
    "    df_user = df_transcript_turn[mask_user]\n",
    "\n",
    "    df_concat = pd.concat([df_system, df_user])\n",
    "    df_concat = df_concat.sort_values(\"start_time\").reset_index(drop=True)\n",
    "\n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a generator of two adjacent turns in the \"system-speech\" tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_turn_generator(\n",
    "        df_transcript: pd.DataFrame\n",
    ") -> Generator[Tuple[pd.Series, pd.Series], None, None]:\n",
    "    mask_user = (df_transcript[\"speaker\"] == \"user\")\n",
    "\n",
    "    mask_intro = (df_transcript[\"topic\"] == \"intro\")\n",
    "    mask_closing = (df_transcript[\"topic\"] == \"closing\")\n",
    "    mask_topic = mask_intro | mask_closing\n",
    "\n",
    "    mask = mask_user & ~mask_topic\n",
    "\n",
    "    df_transcript_masked = df_transcript[mask]\n",
    "    for idx_user in df_transcript_masked.index:\n",
    "        idx_system = idx_user - 1\n",
    "\n",
    "        turn_system = df_transcript.loc[idx_system, :]\n",
    "        turn_user = df_transcript.loc[idx_user, :]\n",
    "\n",
    "        yield turn_system, turn_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block gets start and end time of two adjacent system's turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end_time(turn_system: pd.Series, turn_user: pd.Series) -> Tuple[float, float]:\n",
    "    start_time = turn_system[\"start_time\"]\n",
    "    end_time = turn_user[\"end_time\"]\n",
    "\n",
    "    start_time /= 1000\n",
    "    end_time /= 1000\n",
    "\n",
    "    return start_time, end_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block extract intervals based on start and end times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_intervals(\n",
    "        textgrid: TextGrid, \n",
    "        target_tier: str,\n",
    "        start_time: float, \n",
    "        end_time: float\n",
    ") -> List[Interval]:\n",
    "    \n",
    "    interval_list = []\n",
    "    tier = textgrid[target_tier]\n",
    "\n",
    "    for interval in tier:\n",
    "        if interval.text == \"\":\n",
    "            continue\n",
    "\n",
    "        if (interval.xmin >= start_time) and (interval.xmax <= end_time):\n",
    "            interval_list.append(interval)\n",
    "\n",
    "        if interval.xmax > end_time:\n",
    "            break\n",
    "\n",
    "    return interval_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to count the number of syllables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(interval_list: List[Interval]) -> int:\n",
    "    n_syl = 0\n",
    "    for interval in interval_list:\n",
    "        text = interval.text\n",
    "        if text == \"\":\n",
    "            continue\n",
    "        \n",
    "        for word in text.split(\" \"):\n",
    "            n_syl += syllables.estimate(word)\n",
    "\n",
    "    return n_syl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines two functions to get earliest and latest timestamps and to calcuate speech duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earliest_lates_timestamp(interval_list: List[Interval]) -> Tuple[float, float]:\n",
    "    earliest_time = 60 * 60 # 1 hour\n",
    "    latest_time = -1\n",
    "\n",
    "    for interval in interval_list:\n",
    "        if interval.text == \"\":\n",
    "            continue\n",
    "\n",
    "        if earliest_time > interval.xmin:\n",
    "            earliest_time = interval.xmin\n",
    "        if latest_time < interval.xmax:\n",
    "            latest_time = interval.xmax\n",
    "\n",
    "    return earliest_time, latest_time\n",
    "\n",
    "\n",
    "def calculate_speech_duration(\n",
    "        transcript_list: List[Interval],\n",
    "        pause_list: List[Interval],\n",
    "        filler_list: List[Interval],\n",
    "        disfluency_list: List[Interval]\n",
    ") -> float:\n",
    "    earliest_time, latest_time = get_earliest_lates_timestamp(transcript_list)\n",
    "\n",
    "    for interval_list in [pause_list, filler_list, disfluency_list]:\n",
    "        if len(interval_list) == 0:\n",
    "            continue\n",
    "\n",
    "        start_time, end_time = get_earliest_lates_timestamp(interval_list)\n",
    "        if earliest_time > start_time:\n",
    "            earliest_time = start_time\n",
    "        if latest_time < end_time:\n",
    "            latest_time = end_time\n",
    "\n",
    "    return latest_time - earliest_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines two function to get mid-clause and end-clause pause duration list and the number of filled pauses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pause_durations(pause_list: List[Interval]) -> Tuple[List[float], List[float]]:\n",
    "    mcp = []\n",
    "    ecp = []\n",
    "    for interval in pause_list:\n",
    "        if interval.text == \"\":\n",
    "            continue\n",
    "\n",
    "        duration = interval.xmax - interval.xmin\n",
    "        if interval.text == \"CI\":\n",
    "            mcp.append(duration)\n",
    "            continue\n",
    "\n",
    "        if interval.text == \"CE\":\n",
    "            ecp.append(duration)\n",
    "    \n",
    "    return mcp, ecp\n",
    "\n",
    "def count_filled_pauses(filler_list: List[Interval]) -> int:\n",
    "    n_filler = 0\n",
    "    for interval in filler_list:\n",
    "        if interval.text == \"\":\n",
    "            continue\n",
    "\n",
    "        n_filler += 1\n",
    "\n",
    "    return n_filler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to count disfluency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_disfluency(disfluency_list: List[Interval]) -> int:\n",
    "    n_disfl = 0\n",
    "    for interval in disfluency_list:\n",
    "        if interval.text == \"\":\n",
    "            continue\n",
    "\n",
    "        n_disfl += 1\n",
    "\n",
    "    return n_disfl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to get a turn id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turn_id(df_transcript_turn: pd.DataFrame, idx: int) -> str:\n",
    "    mask_user = (df_transcript_turn[\"speaker\"] == \"user\")\n",
    "\n",
    "    mask_intro = (df_transcript_turn[\"topic\"] == \"intro\")\n",
    "    mask_closing = (df_transcript_turn[\"topic\"] == \"closing\")\n",
    "    mask_topic = mask_intro | mask_closing\n",
    "\n",
    "    mask = mask_user & (~mask_topic)\n",
    "\n",
    "    df_user = df_transcript_turn[mask].reset_index(drop=False)\n",
    "\n",
    "    turn_id = df_user.at[idx, \"index\"]\n",
    "    turn_id = str(int(turn_id)).zfill(3)\n",
    "\n",
    "    return turn_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Calculate UF Measures\n",
    "\n",
    "This section calculate UF measures.\n",
    "The following code block constructs a UF measure extractor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = UtteranceFluencyFeatureExtractor(\n",
    "    rep=False, rpr=False, fs=False, rf=False, \n",
    "    ptr=False, ar_w=False, sr_w=False, mlr_w=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block claculate UF measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_list = []\n",
    "\n",
    "for textgrid_path in textgrid_path_generator():\n",
    "    textgrid = load_textgrid(textgrid_path)\n",
    "    \n",
    "    df_transcript = load_df_transcript(textgrid_path)\n",
    "    df_transcript_turn = convert_turnwise(df_transcript)\n",
    "    df_transcript = concat_transcript(df_transcript, df_transcript_turn)\n",
    "    \n",
    "    for idx, (turn_system, turn_user) in enumerate(system_turn_generator(df_transcript)):\n",
    "        start_time, end_time = get_start_end_time(turn_system, turn_user)\n",
    "\n",
    "        transcript_list = extract_intervals(textgrid, \"transcript\", start_time, end_time)\n",
    "        pause_list = extract_intervals(textgrid, \"pause\", start_time, end_time)\n",
    "        filler_list = extract_intervals(textgrid, \"filler\", start_time, end_time)\n",
    "        disfluency_list = extract_intervals(textgrid, \"disfluency\", start_time, end_time)\n",
    "\n",
    "        n_syl_unpruned = count_syllables(transcript_list)\n",
    "        n_syl_filler = count_syllables(filler_list)\n",
    "        n_syl_disfl = count_syllables(disfluency_list)\n",
    "        n_syl_pruned = n_syl_unpruned - n_syl_filler - n_syl_disfl\n",
    "\n",
    "        duration = calculate_speech_duration(\n",
    "            transcript_list, pause_list,\n",
    "            filler_list, disfluency_list\n",
    "        )\n",
    "\n",
    "        mcp, ecp = extract_pause_durations(pause_list)\n",
    "        n_filler = count_filled_pauses(filler_list)\n",
    "\n",
    "        n_disfl = count_disfluency(disfluency_list)\n",
    "\n",
    "        params = {\n",
    "            \"n_word\": 1,\n",
    "            \"dur\": duration,\n",
    "            \"syl\": np.array([n_syl_pruned]),\n",
    "            \"mc\": np.array(mcp),\n",
    "            \"ec\": np.array(ecp),\n",
    "            \"repetition\": n_disfl,\n",
    "            \"self_repair\": 0,\n",
    "            \"false_start\": 0,\n",
    "            \"repair_false\": 0,\n",
    "            \"filled\": n_filler\n",
    "        }\n",
    "\n",
    "        measure = extractor.extract_by_parameters(params)\n",
    "        turn_id = get_turn_id(df_transcript_turn, idx)\n",
    "        uid = textgrid_path.stem.split(\"_\")[1]\n",
    "\n",
    "        measure = [f\"{uid}_{turn_id}\"] + measure\n",
    "\n",
    "        measure_list.append(measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a pandas' DataFramse from claculated UF measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>speech_rate</th>\n",
       "      <th>mid_clause_pause_ratio</th>\n",
       "      <th>end_clause_pause_ratio</th>\n",
       "      <th>mid_clause_p-dur</th>\n",
       "      <th>end_clause_p-dur</th>\n",
       "      <th>filled_pause_ratio</th>\n",
       "      <th>dysfluency_ratio</th>\n",
       "      <th>dysfluency_rate</th>\n",
       "      <th>articulation_rate</th>\n",
       "      <th>mean_length_of_run</th>\n",
       "      <th>mean_pause_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001_009</td>\n",
       "      <td>3.474903</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.245283</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001_011</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001_013</td>\n",
       "      <td>1.422107</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.974295</td>\n",
       "      <td>0.350646</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.146786</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>0.870354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001_015</td>\n",
       "      <td>2.698145</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.170361</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.883256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001_017</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.624947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.039199</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.624947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>085_043</td>\n",
       "      <td>0.702988</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>085_045</td>\n",
       "      <td>1.494612</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.849370</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.069517</td>\n",
       "      <td>2.372821</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>0.819085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>085_047</td>\n",
       "      <td>1.128757</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>1.333889</td>\n",
       "      <td>1.008750</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.091876</td>\n",
       "      <td>1.949671</td>\n",
       "      <td>3.185185</td>\n",
       "      <td>1.233846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>085_049</td>\n",
       "      <td>1.116784</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>1.021429</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.079770</td>\n",
       "      <td>1.920439</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.971481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>085_051</td>\n",
       "      <td>1.017294</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>1.244297</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.672500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1743 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid  speech_rate  mid_clause_pause_ratio  end_clause_pause_ratio  \\\n",
       "0     001_009     3.474903                0.111111                0.000000   \n",
       "1     001_011     4.000000                0.000000                0.000000   \n",
       "2     001_013     1.422107                0.227273                0.045455   \n",
       "3     001_015     2.698145                0.062500                0.000000   \n",
       "4     001_017     1.625000                0.076923                0.000000   \n",
       "...       ...          ...                     ...                     ...   \n",
       "1738  085_043     0.702988                0.500000                0.000000   \n",
       "1739  085_045     1.494612                0.232558                0.069767   \n",
       "1740  085_047     1.128757                0.209302                0.093023   \n",
       "1741  085_049     1.116784                0.285714                0.100000   \n",
       "1742  085_051     1.017294                0.166667                0.100000   \n",
       "\n",
       "      mid_clause_p-dur  end_clause_p-dur  filled_pause_ratio  \\\n",
       "0             0.470000          0.000000            0.000000   \n",
       "1             0.000000          0.000000            0.000000   \n",
       "2             0.974295          0.350646            0.090909   \n",
       "3             0.883256          0.000000            0.062500   \n",
       "4             1.624947          0.000000            0.076923   \n",
       "...                ...               ...                 ...   \n",
       "1738          0.325000          0.000000            0.250000   \n",
       "1739          0.810000          0.849370            0.069767   \n",
       "1740          1.333889          1.008750            0.081395   \n",
       "1741          0.954000          1.021429            0.157143   \n",
       "1742          0.722000          0.590000            0.133333   \n",
       "\n",
       "      dysfluency_ratio  dysfluency_rate  articulation_rate  \\\n",
       "0             0.000000         0.000000           4.245283   \n",
       "1             0.000000         0.000000           4.000000   \n",
       "2             0.000000         0.000000           2.146786   \n",
       "3             0.000000         0.000000           3.170361   \n",
       "4             0.000000         0.000000           2.039199   \n",
       "...                ...              ...                ...   \n",
       "1738          0.000000         0.000000           0.793651   \n",
       "1739          0.046512         0.069517           2.372821   \n",
       "1740          0.081395         0.091876           1.949671   \n",
       "1741          0.071429         0.079770           1.920439   \n",
       "1742          0.033333         0.033910           1.244297   \n",
       "\n",
       "      mean_length_of_run  mean_pause_duration  \n",
       "0               4.500000             0.470000  \n",
       "1               6.000000             0.000000  \n",
       "2               3.142857             0.870354  \n",
       "3               8.000000             0.883256  \n",
       "4               6.500000             1.624947  \n",
       "...                  ...                  ...  \n",
       "1738            1.333333             0.325000  \n",
       "1739            3.071429             0.819085  \n",
       "1740            3.185185             1.233846  \n",
       "1741            2.500000             0.971481  \n",
       "1742            3.333333             0.672500  \n",
       "\n",
       "[1743 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_names = extractor.check_feature_names()\n",
    "columns = [\"uid\"] + measure_names\n",
    "\n",
    "df_measures = pd.DataFrame(measure_list, columns=columns)\n",
    "df_measures = df_measures.sort_values(\"uid\").reset_index(drop=True)\n",
    "df_measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block saves the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = DATA_DIR / \"WoZ_Interview/09_UF_Measures/uf_measures_manu_pruned.csv\"\n",
    "\n",
    "df_measures.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teai-incremental-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
