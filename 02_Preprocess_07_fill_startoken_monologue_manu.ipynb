{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/11 (Sat) | Preprocess\n",
    "\n",
    "# Post-Process for Forced Alignment Outputs of Monologue Data (Manual Transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook fills star tokens in the forced alignment outputs focusing on monologue data.\n",
    "The procedure consists of the followign stages.\n",
    "\n",
    "1. Load a TextGrid file\n",
    "2. Load a corresponding forced alignment output file\n",
    "3. Preprocess the TextGrid\n",
    "4. Fill star tokens (i.e., unsupported characters in wav2vec forced alignment)\n",
    "5. Save the result\n",
    "\n",
    "The following code block loads required packages and define global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Generator\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textgrids import TextGrid\n",
    "\n",
    "DATA_DIR = Path(\"/home/matsuura/Development/app/feature_extraction_api/experiment/data\")\n",
    "\n",
    "TASK = [\"Arg_Oly\", \"Cartoon\", \"RtSwithoutRAA\", \"RtSwithRAA\"]\n",
    "\n",
    "PUNCTUATIONS = [\".\", \",\", \":\", \"?\", \"!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Define Functions\n",
    "\n",
    "This section defines functions to complete the post-process.\n",
    "The following code block defines a generator of TextGrid path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textgrid_path_generator(task: str) -> Generator[Path, None, None]:\n",
    "    load_dir = DATA_DIR / f\"{task}/01_Manual_TextGrid\"\n",
    "\n",
    "    for textgrid_path in load_dir.glob(\"*.TextGrid\"):\n",
    "        yield textgrid_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to remove prefix of the TextGrid filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(textgrid_path: Path, task: str) -> str:\n",
    "    participant_id = textgrid_path.stem[:4]\n",
    "    filename = f\"{participant_id}_{task}\"\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to load a forced alignment output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fa_output(filename: str, task: str) -> pd.DataFrame:\n",
    "    fa_output_path = DATA_DIR / f\"{task}/06_FA_csv_Manu/{filename}.csv\"\n",
    "    df_fa = pd.read_csv(fa_output_path)\n",
    "\n",
    "    return df_fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to extract texts from a TextGrid file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts_from_textgrid(textgrid_path: Path) -> List[str]:\n",
    "    textgrid = TextGrid(str(textgrid_path))\n",
    "    transcript_tier = textgrid[\"Transcript\"]\n",
    "    \n",
    "    texts = []\n",
    "    for interval in transcript_tier:\n",
    "        text = interval.text\n",
    "        texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block define a function to transform the extracted texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_texts(texts: List[str]) -> np.ndarray:\n",
    "    # 1. transform list 2 str\n",
    "    fa_transcript = \" \".join(texts)\n",
    "\n",
    "    # 2. remove disfluency tags\n",
    "    fa_transcript = fa_transcript.replace(\"{\", \" \")\n",
    "    fa_transcript = fa_transcript.replace(\"}\", \" \")\n",
    "\n",
    "    # 3. remove other punctuations\n",
    "    for punct in PUNCTUATIONS:\n",
    "        fa_transcript = fa_transcript.replace(punct, \" \")\n",
    "    fa_transcript = fa_transcript.replace(\"-\", \"\")\n",
    "    fa_transcript = fa_transcript.replace(\"Ã©\", \"e\")\n",
    "\n",
    "    # 4. lower transcript\n",
    "    fa_transcript = fa_transcript.lower()\n",
    "\n",
    "    # 5. remove extra pauses\n",
    "    while \"  \" in fa_transcript:\n",
    "        fa_transcript = fa_transcript.replace(\"  \", \" \")\n",
    "    \n",
    "    if fa_transcript[0] == \" \":\n",
    "        fa_transcript = fa_transcript[1:]\n",
    "    if fa_transcript[-1] == \" \":\n",
    "        fa_transcript = fa_transcript[:-1]\n",
    "\n",
    "    return np.array(fa_transcript.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to check the number of words in a TextGrid transcript and the corresponding forced alignment output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_length(word_list: np.ndarray, df_fa: pd.DataFrame) -> bool:\n",
    "    return len(word_list) == len(df_fa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to fill star tokens in a forced alignment output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_startokens(word_list: np.ndarray, df_fa: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_fa_filled = df_fa.copy(deep=True)\n",
    "\n",
    "    mask_star = (df_fa[\"word\"] == \"*\").to_numpy()\n",
    "\n",
    "    df_fa_filled.loc[mask_star, \"word\"] = word_list[mask_star]\n",
    "\n",
    "    return df_fa_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines a function to save a forced alignment output in which star tokens are filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_fa_filled(df_fa_filled: pd.DataFrame, filename: str, task: str) -> None:\n",
    "    save_path = DATA_DIR / f\"{task}/06_FA_csv_Manu/{filename}_filled.csv\"\n",
    "\n",
    "    df_fa_filled.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Conduct Post-Process\n",
    "\n",
    "The following code block conducts post-process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in TASK:\n",
    "    for textgrid_path in textgrid_path_generator(task):\n",
    "        texts = extract_texts_from_textgrid(textgrid_path)\n",
    "        \n",
    "        filename = get_filename(textgrid_path, task)\n",
    "        df_fa = load_fa_output(filename, task)\n",
    "\n",
    "        word_list = transform_texts(texts)\n",
    "\n",
    "        if is_same_length(word_list, df_fa):\n",
    "            df_fa_filled = fill_startokens(word_list, df_fa)\n",
    "            save_df_fa_filled(df_fa_filled, filename, task)\n",
    "\n",
    "        else:\n",
    "            print(f\"[Error] {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teai-incremental-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
